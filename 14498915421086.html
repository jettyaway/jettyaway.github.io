<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  redis3.0 config - IT framer
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="IT framer" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:www.blacklight.xin ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; IT framer</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
       
       <li><a href="index.html">HOME</a></li>
    <li><a href="archives.html">Archives</a></li>
    <li><a href="about.html">ABOUT</a></li>

    <li><label>Categories</label></li>

        
            <li><a href="flume.html">flume</a></li>
        
            <li><a href="java.html">java</a></li>
        
            <li><a href="kafka.html">kafka</a></li>
        
            <li><a href="awk.html">awk</a></li>
        
            <li><a href="storm.html">storm</a></li>
        
            <li><a href="spark.html">spark</a></li>
        
            <li><a href="redis.html">redis</a></li>
        
            <li><a href="liunx.html">linux</a></li>
        
            <li><a href="zookeeper.html">zookeeper</a></li>
        
            <li><a href="hive.html">hive</a></li>
        
            <li><a href="maven.html">maven</a></li>
        
            <li><a href="shell.html">shell</a></li>
        
            <li><a href="docker.html">docker</a></li>
        
            <li><a href="mysql.html">mysql</a></li>
        
            <li><a href="datahole.html">datahole</a></li>
        
            <li><a href="scala.html">scala</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
  $(function(){
    $('#menu_item_index').addClass('is_active');
  });
</script>
<div class="row">
  <div class="large-8 medium-8 columns">
      <div class="markdown-body article-wrap">
       <div class="article">
          
          <h1>redis3.0 config</h1>
     
        <div class="read-more clearfix">
          <span class="date">2015/12/12</span>

          <span>posted in&nbsp;</span> 
          
              <span class="posted-in"><a href='redis.html'>redis</a></span>
           
         
          <span class="comments">
            

            
          </span>

        </div>
      </div><!-- article -->

      <div class="article-content">
      <span id="more"></span><!-- more -->

<h1 id="toc_0">Redis configuration file example</h1>

<h1 id="toc_1">Note on units: when memory size is needed, it is possible to specify</h1>

<h1 id="toc_2">it in the usual form of 1k 5GB 4M and so forth:</h1>

<h1 id="toc_3">1k =&gt; 1000 bytes</h1>

<h1 id="toc_4">1kb =&gt; 1024 bytes</h1>

<h1 id="toc_5">1m =&gt; 1000000 bytes</h1>

<h1 id="toc_6">1mb =&gt; 1024*1024 bytes</h1>

<h1 id="toc_7">1g =&gt; 1000000000 bytes</h1>

<h1 id="toc_8">1gb =&gt; 1024<em>1024</em>1024 bytes</h1>

<h1 id="toc_9">units are case insensitive so 1GB 1Gb 1gB are all the same.</h1>

<!-- more -->

<h6 id="toc_10">############################ INCLUDES</h6>

<h1 id="toc_11">Include one or more other config files here.  This is useful if you</h1>

<h1 id="toc_12">have a standard template that goes to all Redis servers but also need</h1>

<h1 id="toc_13">to customize a few per-server settings.  Include files can include</h1>

<h1 id="toc_14">other files, so use this wisely.</h1>

<h1 id="toc_15">Notice option &quot;include&quot; won&#39;t be rewritten by command &quot;CONFIG REWRITE&quot;</h1>

<h1 id="toc_16">from admin or Redis Sentinel. Since Redis always uses the last processed</h1>

<h1 id="toc_17">line as value of a configuration directive, you&#39;d better put includes</h1>

<h1 id="toc_18">at the beginning of this file to avoid overwriting config change at runtime.</h1>

<h1 id="toc_19">If instead you are interested in using includes to override configuration</h1>

<h1 id="toc_20">options, it is better to use include as the last line.</h1>

<h1 id="toc_21">include /path/to/local.conf</h1>

<h1 id="toc_22">include /path/to/other.conf</h1>

<h6 id="toc_23">########################## GENERAL</h6>

<h1 id="toc_24">By default Redis does not run as a daemon. Use &#39;yes&#39; if you need it.</h1>

<h1 id="toc_25">Note that Redis will write a pid file in /var/run/redis.pid when daemonized.</h1>

<p>daemonize yes</p>

<h1 id="toc_26">When running daemonized, Redis writes a pid file in /var/run/redis.pid by</h1>

<h1 id="toc_27">default. You can specify a custom pid file location here.</h1>

<p>pidfile /data/redis/data/redis-6380.pid</p>

<h1 id="toc_28">Accept connections on the specified port, default is 6379.</h1>

<h1 id="toc_29">If port 0 is specified Redis will not listen on a TCP socket.</h1>

<p>port 6380</p>

<h1 id="toc_30">TCP listen() backlog.</h1>

<h1 id="toc_31">In high requests-per-second environments you need an high backlog in order</h1>

<h1 id="toc_32">to avoid slow clients connections issues. Note that the Linux kernel</h1>

<h1 id="toc_33">will silently truncate it to the value of /proc/sys/net/core/somaxconn so</h1>

<h1 id="toc_34">make sure to raise both the value of somaxconn and tcp_max_syn_backlog</h1>

<h1 id="toc_35">in order to get the desired effect.</h1>

<p>tcp-backlog 511</p>

<h1 id="toc_36">By default Redis listens for connections from all the network interfaces</h1>

<h1 id="toc_37">available on the server. It is possible to listen to just one or multiple</h1>

<h1 id="toc_38">interfaces using the &quot;bind&quot; configuration directive, followed by one or</h1>

<h1 id="toc_39">more IP addresses.</h1>

<h1 id="toc_40">Examples:</h1>

<h1 id="toc_41">bind 192.168.1.100 10.0.0.1</h1>

<p>bind 192.168.100.30</p>

<h1 id="toc_42">Specify the path for the Unix socket that will be used to listen for</h1>

<h1 id="toc_43">incoming connections. There is no default, so Redis will not listen</h1>

<h1 id="toc_44">on a unix socket when not specified.</h1>

<p>unixsocket /data/reids/data/redis-6380.sock<br/>
unixsocketperm 700</p>

<h1 id="toc_45">Close the connection after a client is idle for N seconds (0 to disable)</h1>

<p>timeout 300</p>

<h1 id="toc_46">TCP keepalive.</h1>

<h1 id="toc_47">If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence</h1>

<h1 id="toc_48">of communication. This is useful for two reasons:</h1>

<h1 id="toc_49">1) Detect dead peers.</h1>

<h1 id="toc_50">2) Take the connection alive from the point of view of network</h1>

<h1 id="toc_51">equipment in the middle.</h1>

<h1 id="toc_52">On Linux, the specified value (in seconds) is the period used to send ACKs.</h1>

<h1 id="toc_53">Note that to close the connection the double of the time is needed.</h1>

<h1 id="toc_54">On other kernels the period depends on the kernel configuration.</h1>

<h1 id="toc_55">A reasonable value for this option is 60 seconds.</h1>

<p>tcp-keepalive 0</p>

<h1 id="toc_56">Specify the server verbosity level.</h1>

<h1 id="toc_57">This can be one of:</h1>

<h1 id="toc_58">debug (a lot of information, useful for development/testing)</h1>

<h1 id="toc_59">verbose (many rarely useful info, but not a mess like the debug level)</h1>

<h1 id="toc_60">notice (moderately verbose, what you want in production probably)</h1>

<h1 id="toc_61">warning (only very important / critical messages are logged)</h1>

<p>loglevel verbose</p>

<h1 id="toc_62">Specify the log file name. Also the empty string can be used to force</h1>

<h1 id="toc_63">Redis to log on the standard output. Note that if you use standard</h1>

<h1 id="toc_64">output for logging but daemonize, logs will be sent to /dev/null</h1>

<p>logfile /data/redis/logs/redis-6380.log</p>

<h1 id="toc_65">To enable logging to the system logger, just set &#39;syslog-enabled&#39; to yes,</h1>

<h1 id="toc_66">and optionally update the other syslog parameters to suit your needs.</h1>

<h1 id="toc_67">syslog-enabled no</h1>

<h1 id="toc_68">Specify the syslog identity.</h1>

<h1 id="toc_69">syslog-ident redis</h1>

<h1 id="toc_70">Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.</h1>

<h1 id="toc_71">syslog-facility local0</h1>

<h1 id="toc_72">Set the number of databases. The default database is DB 0, you can select</h1>

<h1 id="toc_73">a different one on a per-connection basis using SELECT <dbid> where</h1>

<h1 id="toc_74">dbid is a number between 0 and &#39;databases&#39;-1</h1>

<p>databases 16</p>

<h6 id="toc_75">########################## SNAPSHOTTING</h6>

<h1 id="toc_76">Save the DB on disk:</h1>

<h1 id="toc_77">save <seconds> <changes></h1>

<h1 id="toc_78">Will save the DB if both the given number of seconds and the given</h1>

<h1 id="toc_79">number of write operations against the DB occurred.</h1>

<h1 id="toc_80">In the example below the behaviour will be to save:</h1>

<h1 id="toc_81">after 900 sec (15 min) if at least 1 key changed</h1>

<h1 id="toc_82">after 300 sec (5 min) if at least 10 keys changed</h1>

<h1 id="toc_83">after 60 sec if at least 10000 keys changed</h1>

<h1 id="toc_84">Note: you can disable saving completely by commenting out all &quot;save&quot; lines.</h1>

<h1 id="toc_85">It is also possible to remove all the previously configured save</h1>

<h1 id="toc_86">points by adding a save directive with a single empty string argument</h1>

<h1 id="toc_87">like in the following example:</h1>

<h1 id="toc_88">save &quot;&quot;</h1>

<p>save 900 1<br/>
save 300 10<br/>
save 60 10000</p>

<h1 id="toc_89">By default Redis will stop accepting writes if RDB snapshots are enabled</h1>

<h1 id="toc_90">(at least one save point) and the latest background save failed.</h1>

<h1 id="toc_91">This will make the user aware (in a hard way) that data is not persisting</h1>

<h1 id="toc_92">on disk properly, otherwise chances are that no one will notice and some</h1>

<h1 id="toc_93">disaster will happen.</h1>

<h1 id="toc_94">If the background saving process will start working again Redis will</h1>

<h1 id="toc_95">automatically allow writes again.</h1>

<h1 id="toc_96">However if you have setup your proper monitoring of the Redis server</h1>

<h1 id="toc_97">and persistence, you may want to disable this feature so that Redis will</h1>

<h1 id="toc_98">continue to work as usual even if there are problems with disk,</h1>

<h1 id="toc_99">permissions, and so forth.</h1>

<p>stop-writes-on-bgsave-error yes</p>

<h1 id="toc_100">Compress string objects using LZF when dump .rdb databases?</h1>

<h1 id="toc_101">For default that&#39;s set to &#39;yes&#39; as it&#39;s almost always a win.</h1>

<h1 id="toc_102">If you want to save some CPU in the saving child set it to &#39;no&#39; but</h1>

<h1 id="toc_103">the dataset will likely be bigger if you have compressible values or keys.</h1>

<p>rdbcompression yes</p>

<h1 id="toc_104">Since version 5 of RDB a CRC64 checksum is placed at the end of the file.</h1>

<h1 id="toc_105">This makes the format more resistant to corruption but there is a performance</h1>

<h1 id="toc_106">hit to pay (around 10%) when saving and loading RDB files, so you can disable it</h1>

<h1 id="toc_107">for maximum performances.</h1>

<h1 id="toc_108">RDB files created with checksum disabled have a checksum of zero that will</h1>

<h1 id="toc_109">tell the loading code to skip the check.</h1>

<p>rdbchecksum yes</p>

<h1 id="toc_110">The filename where to dump the DB</h1>

<p>dbfilename dump-6380.rdb</p>

<h1 id="toc_111">The working directory.</h1>

<h1 id="toc_112">The DB will be written inside this directory, with the filename specified</h1>

<h1 id="toc_113">above using the &#39;dbfilename&#39; configuration directive.</h1>

<h1 id="toc_114">The Append Only File will also be created inside this directory.</h1>

<h1 id="toc_115">Note that you must specify a directory here, not a file name.</h1>

<p>dir /data/redis/data/</p>

<h6 id="toc_116">########################### REPLICATION</h6>

<h1 id="toc_117">Master-Slave replication. Use slaveof to make a Redis instance a copy of</h1>

<h1 id="toc_118">another Redis server. A few things to understand ASAP about Redis replication.</h1>

<h1 id="toc_119">1) Redis replication is asynchronous, but you can configure a master to</h1>

<h1 id="toc_120">stop accepting writes if it appears to be not connected with at least</h1>

<h1 id="toc_121">a given number of slaves.</h1>

<h1 id="toc_122">2) Redis slaves are able to perform a partial resynchronization with the</h1>

<h1 id="toc_123">master if the replication link is lost for a relatively small amount of</h1>

<h1 id="toc_124">time. You may want to configure the replication backlog size (see the next</h1>

<h1 id="toc_125">sections of this file) with a sensible value depending on your needs.</h1>

<h1 id="toc_126">3) Replication is automatic and does not need user intervention. After a</h1>

<h1 id="toc_127">network partition slaves automatically try to reconnect to masters</h1>

<h1 id="toc_128">and resynchronize with them.</h1>

<h1 id="toc_129">slaveof <masterip> <masterport></h1>

<h1 id="toc_130">If the master is password protected (using the &quot;requirepass&quot; configuration</h1>

<h1 id="toc_131">directive below) it is possible to tell the slave to authenticate before</h1>

<h1 id="toc_132">starting the replication synchronization process, otherwise the master will</h1>

<h1 id="toc_133">refuse the slave request.</h1>

<h1 id="toc_134">masterauth <master-password></h1>

<h1 id="toc_135">When a slave loses its connection with the master, or when the replication</h1>

<h1 id="toc_136">is still in progress, the slave can act in two different ways:</h1>

<h1 id="toc_137">1) if slave-serve-stale-data is set to &#39;yes&#39; (the default) the slave will</h1>

<h1 id="toc_138">still reply to client requests, possibly with out of date data, or the</h1>

<h1 id="toc_139">data set may just be empty if this is the first synchronization.</h1>

<h1 id="toc_140">2) if slave-serve-stale-data is set to &#39;no&#39; the slave will reply with</h1>

<h1 id="toc_141">an error &quot;SYNC with master in progress&quot; to all the kind of commands</h1>

<h1 id="toc_142">but to INFO and SLAVEOF.</h1>

<p>slave-serve-stale-data yes</p>

<h1 id="toc_143">You can configure a slave instance to accept writes or not. Writing against</h1>

<h1 id="toc_144">a slave instance may be useful to store some ephemeral data (because data</h1>

<h1 id="toc_145">written on a slave will be easily deleted after resync with the master) but</h1>

<h1 id="toc_146">may also cause problems if clients are writing to it because of a</h1>

<h1 id="toc_147">misconfiguration.</h1>

<h1 id="toc_148">Since Redis 2.6 by default slaves are read-only.</h1>

<h1 id="toc_149">Note: read only slaves are not designed to be exposed to untrusted clients</h1>

<h1 id="toc_150">on the internet. It&#39;s just a protection layer against misuse of the instance.</h1>

<h1 id="toc_151">Still a read only slave exports by default all the administrative commands</h1>

<h1 id="toc_152">such as CONFIG, DEBUG, and so forth. To a limited extent you can improve</h1>

<h1 id="toc_153">security of read only slaves using &#39;rename-command&#39; to shadow all the</h1>

<h1 id="toc_154">administrative / dangerous commands.</h1>

<p>slave-read-only yes</p>

<h1 id="toc_155">Replication SYNC strategy: disk or socket.</h1>

<h1 id="toc_156">-------------------------------------------------------</h1>

<h1 id="toc_157">WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY</h1>

<h1 id="toc_158">-------------------------------------------------------</h1>

<h1 id="toc_159">New slaves and reconnecting slaves that are not able to continue the replication</h1>

<h1 id="toc_160">process just receiving differences, need to do what is called a &quot;full</h1>

<h1 id="toc_161">synchronization&quot;. An RDB file is transmitted from the master to the slaves.</h1>

<h1 id="toc_162">The transmission can happen in two different ways:</h1>

<h1 id="toc_163">1) Disk-backed: The Redis master creates a new process that writes the RDB</h1>

<h1 id="toc_164">file on disk. Later the file is transferred by the parent</h1>

<h1 id="toc_165">process to the slaves incrementally.</h1>

<h1 id="toc_166">2) Diskless: The Redis master creates a new process that directly writes the</h1>

<h1 id="toc_167">RDB file to slave sockets, without touching the disk at all.</h1>

<h1 id="toc_168">With disk-backed replication, while the RDB file is generated, more slaves</h1>

<h1 id="toc_169">can be queued and served with the RDB file as soon as the current child producing</h1>

<h1 id="toc_170">the RDB file finishes its work. With diskless replication instead once</h1>

<h1 id="toc_171">the transfer starts, new slaves arriving will be queued and a new transfer</h1>

<h1 id="toc_172">will start when the current one terminates.</h1>

<h1 id="toc_173">When diskless replication is used, the master waits a configurable amount of</h1>

<h1 id="toc_174">time (in seconds) before starting the transfer in the hope that multiple slaves</h1>

<h1 id="toc_175">will arrive and the transfer can be parallelized.</h1>

<h1 id="toc_176">With slow disks and fast (large bandwidth) networks, diskless replication</h1>

<h1 id="toc_177">works better.</h1>

<p>repl-diskless-sync no</p>

<h1 id="toc_178">When diskless replication is enabled, it is possible to configure the delay</h1>

<h1 id="toc_179">the server waits in order to spawn the child that transfers the RDB via socket</h1>

<h1 id="toc_180">to the slaves.</h1>

<h1 id="toc_181">This is important since once the transfer starts, it is not possible to serve</h1>

<h1 id="toc_182">new slaves arriving, that will be queued for the next RDB transfer, so the server</h1>

<h1 id="toc_183">waits a delay in order to let more slaves arrive.</h1>

<h1 id="toc_184">The delay is specified in seconds, and by default is 5 seconds. To disable</h1>

<h1 id="toc_185">it entirely just set it to 0 seconds and the transfer will start ASAP.</h1>

<p>repl-diskless-sync-delay 5</p>

<h1 id="toc_186">Slaves send PINGs to server in a predefined interval. It&#39;s possible to change</h1>

<h1 id="toc_187">this interval with the repl_ping_slave_period option. The default value is 10</h1>

<h1 id="toc_188">seconds.</h1>

<h1 id="toc_189">repl-ping-slave-period 10</h1>

<h1 id="toc_190">The following option sets the replication timeout for:</h1>

<h1 id="toc_191">1) Bulk transfer I/O during SYNC, from the point of view of slave.</h1>

<h1 id="toc_192">2) Master timeout from the point of view of slaves (data, pings).</h1>

<h1 id="toc_193">3) Slave timeout from the point of view of masters (REPLCONF ACK pings).</h1>

<h1 id="toc_194">It is important to make sure that this value is greater than the value</h1>

<h1 id="toc_195">specified for repl-ping-slave-period otherwise a timeout will be detected</h1>

<h1 id="toc_196">every time there is low traffic between the master and the slave.</h1>

<h1 id="toc_197">repl-timeout 60</h1>

<h1 id="toc_198">Disable TCP_NODELAY on the slave socket after SYNC?</h1>

<h1 id="toc_199">If you select &quot;yes&quot; Redis will use a smaller number of TCP packets and</h1>

<h1 id="toc_200">less bandwidth to send data to slaves. But this can add a delay for</h1>

<h1 id="toc_201">the data to appear on the slave side, up to 40 milliseconds with</h1>

<h1 id="toc_202">Linux kernels using a default configuration.</h1>

<h1 id="toc_203">If you select &quot;no&quot; the delay for data to appear on the slave side will</h1>

<h1 id="toc_204">be reduced but more bandwidth will be used for replication.</h1>

<h1 id="toc_205">By default we optimize for low latency, but in very high traffic conditions</h1>

<h1 id="toc_206">or when the master and slaves are many hops away, turning this to &quot;yes&quot; may</h1>

<h1 id="toc_207">be a good idea.</h1>

<p>repl-disable-tcp-nodelay no</p>

<h1 id="toc_208">Set the replication backlog size. The backlog is a buffer that accumulates</h1>

<h1 id="toc_209">slave data when slaves are disconnected for some time, so that when a slave</h1>

<h1 id="toc_210">wants to reconnect again, often a full resync is not needed, but a partial</h1>

<h1 id="toc_211">resync is enough, just passing the portion of data the slave missed while</h1>

<h1 id="toc_212">disconnected.</h1>

<h1 id="toc_213">The bigger the replication backlog, the longer the time the slave can be</h1>

<h1 id="toc_214">disconnected and later be able to perform a partial resynchronization.</h1>

<h1 id="toc_215">The backlog is only allocated once there is at least a slave connected.</h1>

<h1 id="toc_216">repl-backlog-size 1mb</h1>

<h1 id="toc_217">After a master has no longer connected slaves for some time, the backlog</h1>

<h1 id="toc_218">will be freed. The following option configures the amount of seconds that</h1>

<h1 id="toc_219">need to elapse, starting from the time the last slave disconnected, for</h1>

<h1 id="toc_220">the backlog buffer to be freed.</h1>

<h1 id="toc_221">A value of 0 means to never release the backlog.</h1>

<h1 id="toc_222">repl-backlog-ttl 3600</h1>

<h1 id="toc_223">The slave priority is an integer number published by Redis in the INFO output.</h1>

<h1 id="toc_224">It is used by Redis Sentinel in order to select a slave to promote into a</h1>

<h1 id="toc_225">master if the master is no longer working correctly.</h1>

<h1 id="toc_226">A slave with a low priority number is considered better for promotion, so</h1>

<h1 id="toc_227">for instance if there are three slaves with priority 10, 100, 25 Sentinel will</h1>

<h1 id="toc_228">pick the one with priority 10, that is the lowest.</h1>

<h1 id="toc_229">However a special priority of 0 marks the slave as not able to perform the</h1>

<h1 id="toc_230">role of master, so a slave with priority of 0 will never be selected by</h1>

<h1 id="toc_231">Redis Sentinel for promotion.</h1>

<h1 id="toc_232">By default the priority is 100.</h1>

<p>slave-priority 100</p>

<h1 id="toc_233">It is possible for a master to stop accepting writes if there are less than</h1>

<h1 id="toc_234">N slaves connected, having a lag less or equal than M seconds.</h1>

<h1 id="toc_235">The N slaves need to be in &quot;online&quot; state.</h1>

<h1 id="toc_236">The lag in seconds, that must be &lt;= the specified value, is calculated from</h1>

<h1 id="toc_237">the last ping received from the slave, that is usually sent every second.</h1>

<h1 id="toc_238">This option does not GUARANTEE that N replicas will accept the write, but</h1>

<h1 id="toc_239">will limit the window of exposure for lost writes in case not enough slaves</h1>

<h1 id="toc_240">are available, to the specified number of seconds.</h1>

<h1 id="toc_241">For example to require at least 3 slaves with a lag &lt;= 10 seconds use:</h1>

<h1 id="toc_242">min-slaves-to-write 3</h1>

<h1 id="toc_243">min-slaves-max-lag 10</h1>

<h1 id="toc_244">Setting one or the other to 0 disables the feature.</h1>

<h1 id="toc_245">By default min-slaves-to-write is set to 0 (feature disabled) and</h1>

<h1 id="toc_246">min-slaves-max-lag is set to 10.</h1>

<h6 id="toc_247">############################ SECURITY</h6>

<h1 id="toc_248">Require clients to issue AUTH <PASSWORD> before processing any other</h1>

<h1 id="toc_249">commands.  This might be useful in environments in which you do not trust</h1>

<h1 id="toc_250">others with access to the host running redis-server.</h1>

<h1 id="toc_251">This should stay commented out for backward compatibility and because most</h1>

<h1 id="toc_252">people do not need auth (e.g. they run their own servers).</h1>

<h1 id="toc_253">Warning: since Redis is pretty fast an outside user can try up to</h1>

<h1 id="toc_254">150k passwords per second against a good box. This means that you should</h1>

<h1 id="toc_255">use a very strong password otherwise it will be very easy to break.</h1>

<h1 id="toc_256">requirepass foobared</h1>

<h1 id="toc_257">Command renaming.</h1>

<h1 id="toc_258">It is possible to change the name of dangerous commands in a shared</h1>

<h1 id="toc_259">environment. For instance the CONFIG command may be renamed into something</h1>

<h1 id="toc_260">hard to guess so that it will still be available for internal-use tools</h1>

<h1 id="toc_261">but not available for general clients.</h1>

<h1 id="toc_262">Example:</h1>

<h1 id="toc_263">rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52</h1>

<h1 id="toc_264">It is also possible to completely kill a command by renaming it into</h1>

<h1 id="toc_265">an empty string:</h1>

<h1 id="toc_266">rename-command CONFIG &quot;&quot;</h1>

<h1 id="toc_267">Please note that changing the name of commands that are logged into the</h1>

<h1 id="toc_268">AOF file or transmitted to slaves may cause problems.</h1>

<h6 id="toc_269">############################# LIMITS</h6>

<h1 id="toc_270">Set the max number of connected clients at the same time. By default</h1>

<h1 id="toc_271">this limit is set to 10000 clients, however if the Redis server is not</h1>

<h1 id="toc_272">able to configure the process file limit to allow for the specified limit</h1>

<h1 id="toc_273">the max number of allowed clients is set to the current file limit</h1>

<h1 id="toc_274">minus 32 (as Redis reserves a few file descriptors for internal uses).</h1>

<h1 id="toc_275">Once the limit is reached Redis will close all the new connections sending</h1>

<h1 id="toc_276">an error &#39;max number of clients reached&#39;.</h1>

<h1 id="toc_277">maxclients 10000</h1>

<h1 id="toc_278">Don&#39;t use more memory than the specified amount of bytes.</h1>

<h1 id="toc_279">When the memory limit is reached Redis will try to remove keys</h1>

<h1 id="toc_280">according to the eviction policy selected (see maxmemory-policy).</h1>

<h1 id="toc_281">If Redis can&#39;t remove keys according to the policy, or if the policy is</h1>

<h1 id="toc_282">set to &#39;noeviction&#39;, Redis will start to reply with errors to commands</h1>

<h1 id="toc_283">that would use more memory, like SET, LPUSH, and so on, and will continue</h1>

<h1 id="toc_284">to reply to read-only commands like GET.</h1>

<h1 id="toc_285">This option is usually useful when using Redis as an LRU cache, or to set</h1>

<h1 id="toc_286">a hard memory limit for an instance (using the &#39;noeviction&#39; policy).</h1>

<h1 id="toc_287">WARNING: If you have slaves attached to an instance with maxmemory on,</h1>

<h1 id="toc_288">the size of the output buffers needed to feed the slaves are subtracted</h1>

<h1 id="toc_289">from the used memory count, so that network problems / resyncs will</h1>

<h1 id="toc_290">not trigger a loop where keys are evicted, and in turn the output</h1>

<h1 id="toc_291">buffer of slaves is full with DELs of keys evicted triggering the deletion</h1>

<h1 id="toc_292">of more keys, and so forth until the database is completely emptied.</h1>

<h1 id="toc_293">In short... if you have slaves attached it is suggested that you set a lower</h1>

<h1 id="toc_294">limit for maxmemory so that there is some free RAM on the system for slave</h1>

<h1 id="toc_295">output buffers (but this is not needed if the policy is &#39;noeviction&#39;).</h1>

<h1 id="toc_296">maxmemory <bytes></h1>

<h1 id="toc_297">MAXMEMORY POLICY: how Redis will select what to remove when maxmemory</h1>

<h1 id="toc_298">is reached. You can select among five behaviors:</h1>

<h1 id="toc_299">volatile-lru -&gt; remove the key with an expire set using an LRU algorithm</h1>

<h1 id="toc_300">allkeys-lru -&gt; remove any key according to the LRU algorithm</h1>

<h1 id="toc_301">volatile-random -&gt; remove a random key with an expire set</h1>

<h1 id="toc_302">allkeys-random -&gt; remove a random key, any key</h1>

<h1 id="toc_303">volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)</h1>

<h1 id="toc_304">noeviction -&gt; don&#39;t expire at all, just return an error on write operations</h1>

<h1 id="toc_305">Note: with any of the above policies, Redis will return an error on write</h1>

<h1 id="toc_306">operations, when there are no suitable keys for eviction.</h1>

<h1 id="toc_307">At the date of writing these commands are: set setnx setex append</h1>

<h1 id="toc_308">incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd</h1>

<h1 id="toc_309">sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby</h1>

<h1 id="toc_310">zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby</h1>

<h1 id="toc_311">getset mset msetnx exec sort</h1>

<h1 id="toc_312">The default is:</h1>

<h1 id="toc_313">maxmemory-policy noeviction</h1>

<h1 id="toc_314">LRU and minimal TTL algorithms are not precise algorithms but approximated</h1>

<h1 id="toc_315">algorithms (in order to save memory), so you can tune it for speed or</h1>

<h1 id="toc_316">accuracy. For default Redis will check five keys and pick the one that was</h1>

<h1 id="toc_317">used less recently, you can change the sample size using the following</h1>

<h1 id="toc_318">configuration directive.</h1>

<h1 id="toc_319">The default of 5 produces good enough results. 10 Approximates very closely</h1>

<h1 id="toc_320">true LRU but costs a bit more CPU. 3 is very fast but not very accurate.</h1>

<h1 id="toc_321">maxmemory-samples 5</h1>

<h6 id="toc_322">######################## APPEND ONLY MODE</h6>

<h1 id="toc_323">By default Redis asynchronously dumps the dataset on disk. This mode is</h1>

<h1 id="toc_324">good enough in many applications, but an issue with the Redis process or</h1>

<h1 id="toc_325">a power outage may result into a few minutes of writes lost (depending on</h1>

<h1 id="toc_326">the configured save points).</h1>

<h1 id="toc_327">The Append Only File is an alternative persistence mode that provides</h1>

<h1 id="toc_328">much better durability. For instance using the default data fsync policy</h1>

<h1 id="toc_329">(see later in the config file) Redis can lose just one second of writes in a</h1>

<h1 id="toc_330">dramatic event like a server power outage, or a single write if something</h1>

<h1 id="toc_331">wrong with the Redis process itself happens, but the operating system is</h1>

<h1 id="toc_332">still running correctly.</h1>

<h1 id="toc_333">AOF and RDB persistence can be enabled at the same time without problems.</h1>

<h1 id="toc_334">If the AOF is enabled on startup Redis will load the AOF, that is the file</h1>

<h1 id="toc_335">with the better durability guarantees.</h1>

<h1 id="toc_336">Please check <a href="http://redis.io/topics/persistence">http://redis.io/topics/persistence</a> for more information.</h1>

<p>appendonly yes</p>

<h1 id="toc_337">The name of the append only file (default: &quot;appendonly.aof&quot;)</h1>

<p>appendfilename appendonly-6380.aof</p>

<h1 id="toc_338">The fsync() call tells the Operating System to actually write data on disk</h1>

<h1 id="toc_339">instead of waiting for more data in the output buffer. Some OS will really flush</h1>

<h1 id="toc_340">data on disk, some other OS will just try to do it ASAP.</h1>

<h1 id="toc_341">Redis supports three different modes:</h1>

<h1 id="toc_342">no: don&#39;t fsync, just let the OS flush the data when it wants. Faster.</h1>

<h1 id="toc_343">always: fsync after every write to the append only log. Slow, Safest.</h1>

<h1 id="toc_344">everysec: fsync only one time every second. Compromise.</h1>

<h1 id="toc_345">The default is &quot;everysec&quot;, as that&#39;s usually the right compromise between</h1>

<h1 id="toc_346">speed and data safety. It&#39;s up to you to understand if you can relax this to</h1>

<h1 id="toc_347">&quot;no&quot; that will let the operating system flush the output buffer when</h1>

<h1 id="toc_348">it wants, for better performances (but if you can live with the idea of</h1>

<h1 id="toc_349">some data loss consider the default persistence mode that&#39;s snapshotting),</h1>

<h1 id="toc_350">or on the contrary, use &quot;always&quot; that&#39;s very slow but a bit safer than</h1>

<h1 id="toc_351">everysec.</h1>

<h1 id="toc_352">More details please check the following article:</h1>

<h1 id="toc_353"><a href="http://antirez.com/post/redis-persistence-demystified.html">http://antirez.com/post/redis-persistence-demystified.html</a></h1>

<h1 id="toc_354">If unsure, use &quot;everysec&quot;.</h1>

<h1 id="toc_355">appendfsync always</h1>

<p>appendfsync everysec</p>

<h1 id="toc_356">appendfsync no</h1>

<h1 id="toc_357">When the AOF fsync policy is set to always or everysec, and a background</h1>

<h1 id="toc_358">saving process (a background save or AOF log background rewriting) is</h1>

<h1 id="toc_359">performing a lot of I/O against the disk, in some Linux configurations</h1>

<h1 id="toc_360">Redis may block too long on the fsync() call. Note that there is no fix for</h1>

<h1 id="toc_361">this currently, as even performing fsync in a different thread will block</h1>

<h1 id="toc_362">our synchronous write(2) call.</h1>

<h1 id="toc_363">In order to mitigate this problem it&#39;s possible to use the following option</h1>

<h1 id="toc_364">that will prevent fsync() from being called in the main process while a</h1>

<h1 id="toc_365">BGSAVE or BGREWRITEAOF is in progress.</h1>

<h1 id="toc_366">This means that while another child is saving, the durability of Redis is</h1>

<h1 id="toc_367">the same as &quot;appendfsync none&quot;. In practical terms, this means that it is</h1>

<h1 id="toc_368">possible to lose up to 30 seconds of log in the worst scenario (with the</h1>

<h1 id="toc_369">default Linux settings).</h1>

<h1 id="toc_370">If you have latency problems turn this to &quot;yes&quot;. Otherwise leave it as</h1>

<h1 id="toc_371">&quot;no&quot; that is the safest pick from the point of view of durability.</h1>

<p>no-appendfsync-on-rewrite yes</p>

<h1 id="toc_372">Automatic rewrite of the append only file.</h1>

<h1 id="toc_373">Redis is able to automatically rewrite the log file implicitly calling</h1>

<h1 id="toc_374">BGREWRITEAOF when the AOF log size grows by the specified percentage.</h1>

<h1 id="toc_375">This is how it works: Redis remembers the size of the AOF file after the</h1>

<h1 id="toc_376">latest rewrite (if no rewrite has happened since the restart, the size of</h1>

<h1 id="toc_377">the AOF at startup is used).</h1>

<h1 id="toc_378">This base size is compared to the current size. If the current size is</h1>

<h1 id="toc_379">bigger than the specified percentage, the rewrite is triggered. Also</h1>

<h1 id="toc_380">you need to specify a minimal size for the AOF file to be rewritten, this</h1>

<h1 id="toc_381">is useful to avoid rewriting the AOF file even if the percentage increase</h1>

<h1 id="toc_382">is reached but it is still pretty small.</h1>

<h1 id="toc_383">Specify a percentage of zero in order to disable the automatic AOF</h1>

<h1 id="toc_384">rewrite feature.</h1>

<p>auto-aof-rewrite-percentage 80-100<br/>
auto-aof-rewrite-min-size 64mb</p>

<h1 id="toc_385">An AOF file may be found to be truncated at the end during the Redis</h1>

<h1 id="toc_386">startup process, when the AOF data gets loaded back into memory.</h1>

<h1 id="toc_387">This may happen when the system where Redis is running</h1>

<h1 id="toc_388">crashes, especially when an ext4 filesystem is mounted without the</h1>

<h1 id="toc_389">data=ordered option (however this can&#39;t happen when Redis itself</h1>

<h1 id="toc_390">crashes or aborts but the operating system still works correctly).</h1>

<h1 id="toc_391">Redis can either exit with an error when this happens, or load as much</h1>

<h1 id="toc_392">data as possible (the default now) and start if the AOF file is found</h1>

<h1 id="toc_393">to be truncated at the end. The following option controls this behavior.</h1>

<h1 id="toc_394">If aof-load-truncated is set to yes, a truncated AOF file is loaded and</h1>

<h1 id="toc_395">the Redis server starts emitting a log to inform the user of the event.</h1>

<h1 id="toc_396">Otherwise if the option is set to no, the server aborts with an error</h1>

<h1 id="toc_397">and refuses to start. When the option is set to no, the user requires</h1>

<h1 id="toc_398">to fix the AOF file using the &quot;redis-check-aof&quot; utility before to restart</h1>

<h1 id="toc_399">the server.</h1>

<h1 id="toc_400">Note that if the AOF file will be found to be corrupted in the middle</h1>

<h1 id="toc_401">the server will still exit with an error. This option only applies when</h1>

<h1 id="toc_402">Redis will try to read more data from the AOF file but not enough bytes</h1>

<h1 id="toc_403">will be found.</h1>

<p>aof-load-truncated yes</p>

<h6 id="toc_404">########################## LUA SCRIPTING</h6>

<h1 id="toc_405">Max execution time of a Lua script in milliseconds.</h1>

<h1 id="toc_406">If the maximum execution time is reached Redis will log that a script is</h1>

<h1 id="toc_407">still in execution after the maximum allowed time and will start to</h1>

<h1 id="toc_408">reply to queries with an error.</h1>

<h1 id="toc_409">When a long running script exceeds the maximum execution time only the</h1>

<h1 id="toc_410">SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be</h1>

<h1 id="toc_411">used to stop a script that did not yet called write commands. The second</h1>

<h1 id="toc_412">is the only way to shut down the server in the case a write command was</h1>

<h1 id="toc_413">already issued by the script but the user doesn&#39;t want to wait for the natural</h1>

<h1 id="toc_414">termination of the script.</h1>

<h1 id="toc_415">Set it to 0 or a negative value for unlimited execution without warnings.</h1>

<p>lua-time-limit 5000</p>

<h6 id="toc_416">########################## REDIS CLUSTER</h6>

<h1 id="toc_417">++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</h1>

<h1 id="toc_418">WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however</h1>

<h1 id="toc_419">in order to mark it as &quot;mature&quot; we need to wait for a non trivial percentage</h1>

<h1 id="toc_420">of users to deploy it in production.</h1>

<h1 id="toc_421">++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</h1>

<h1 id="toc_422">Normal Redis instances can&#39;t be part of a Redis Cluster; only nodes that are</h1>

<h1 id="toc_423">started as cluster nodes can. In order to start a Redis instance as a</h1>

<h1 id="toc_424">cluster node enable the cluster support uncommenting the following:</h1>

<p>cluster-enabled yes</p>

<h1 id="toc_425">Every cluster node has a cluster configuration file. This file is not</h1>

<h1 id="toc_426">intended to be edited by hand. It is created and updated by Redis nodes.</h1>

<h1 id="toc_427">Every Redis Cluster node requires a different cluster configuration file.</h1>

<h1 id="toc_428">Make sure that instances running in the same system do not have</h1>

<h1 id="toc_429">overlapping cluster configuration file names.</h1>

<p>cluster-config-file /data/redis/data/nodes-6380.conf</p>

<h1 id="toc_430">Cluster node timeout is the amount of milliseconds a node must be unreachable</h1>

<h1 id="toc_431">for it to be considered in failure state.</h1>

<h1 id="toc_432">Most other internal time limits are multiple of the node timeout.</h1>

<p>cluster-node-timeout 5000</p>

<h1 id="toc_433">A slave of a failing master will avoid to start a failover if its data</h1>

<h1 id="toc_434">looks too old.</h1>

<h1 id="toc_435">There is no simple way for a slave to actually have a exact measure of</h1>

<h1 id="toc_436">its &quot;data age&quot;, so the following two checks are performed:</h1>

<h1 id="toc_437">1) If there are multiple slaves able to failover, they exchange messages</h1>

<h1 id="toc_438">in order to try to give an advantage to the slave with the best</h1>

<h1 id="toc_439">replication offset (more data from the master processed).</h1>

<h1 id="toc_440">Slaves will try to get their rank by offset, and apply to the start</h1>

<h1 id="toc_441">of the failover a delay proportional to their rank.</h1>

<h1 id="toc_442">2) Every single slave computes the time of the last interaction with</h1>

<h1 id="toc_443">its master. This can be the last ping or command received (if the master</h1>

<h1 id="toc_444">is still in the &quot;connected&quot; state), or the time that elapsed since the</h1>

<h1 id="toc_445">disconnection with the master (if the replication link is currently down).</h1>

<h1 id="toc_446">If the last interaction is too old, the slave will not try to failover</h1>

<h1 id="toc_447">at all.</h1>

<h1 id="toc_448">The point &quot;2&quot; can be tuned by user. Specifically a slave will not perform</h1>

<h1 id="toc_449">the failover if, since the last interaction with the master, the time</h1>

<h1 id="toc_450">elapsed is greater than:</h1>

<h1 id="toc_451">(node-timeout * slave-validity-factor) + repl-ping-slave-period</h1>

<h1 id="toc_452">So for example if node-timeout is 30 seconds, and the slave-validity-factor</h1>

<h1 id="toc_453">is 10, and assuming a default repl-ping-slave-period of 10 seconds, the</h1>

<h1 id="toc_454">slave will not try to failover if it was not able to talk with the master</h1>

<h1 id="toc_455">for longer than 310 seconds.</h1>

<h1 id="toc_456">A large slave-validity-factor may allow slaves with too old data to failover</h1>

<h1 id="toc_457">a master, while a too small value may prevent the cluster from being able to</h1>

<h1 id="toc_458">elect a slave at all.</h1>

<h1 id="toc_459">For maximum availability, it is possible to set the slave-validity-factor</h1>

<h1 id="toc_460">to a value of 0, which means, that slaves will always try to failover the</h1>

<h1 id="toc_461">master regardless of the last time they interacted with the master.</h1>

<h1 id="toc_462">(However they&#39;ll always try to apply a delay proportional to their</h1>

<h1 id="toc_463">offset rank).</h1>

<h1 id="toc_464">Zero is the only value able to guarantee that when all the partitions heal</h1>

<h1 id="toc_465">the cluster will always be able to continue.</h1>

<h1 id="toc_466">cluster-slave-validity-factor 10</h1>

<h1 id="toc_467">Cluster slaves are able to migrate to orphaned masters, that are masters</h1>

<h1 id="toc_468">that are left without working slaves. This improves the cluster ability</h1>

<h1 id="toc_469">to resist to failures as otherwise an orphaned master can&#39;t be failed over</h1>

<h1 id="toc_470">in case of failure if it has no working slaves.</h1>

<h1 id="toc_471">Slaves migrate to orphaned masters only if there are still at least a</h1>

<h1 id="toc_472">given number of other working slaves for their old master. This number</h1>

<h1 id="toc_473">is the &quot;migration barrier&quot;. A migration barrier of 1 means that a slave</h1>

<h1 id="toc_474">will migrate only if there is at least 1 other working slave for its master</h1>

<h1 id="toc_475">and so forth. It usually reflects the number of slaves you want for every</h1>

<h1 id="toc_476">master in your cluster.</h1>

<h1 id="toc_477">Default is 1 (slaves migrate only if their masters remain with at least</h1>

<h1 id="toc_478">one slave). To disable migration just set it to a very large value.</h1>

<h1 id="toc_479">A value of 0 can be set but is useful only for debugging and dangerous</h1>

<h1 id="toc_480">in production.</h1>

<h1 id="toc_481">cluster-migration-barrier 1</h1>

<h1 id="toc_482">By default Redis Cluster nodes stop accepting queries if they detect there</h1>

<h1 id="toc_483">is at least an hash slot uncovered (no available node is serving it).</h1>

<h1 id="toc_484">This way if the cluster is partially down (for example a range of hash slots</h1>

<h1 id="toc_485">are no longer covered) all the cluster becomes, eventually, unavailable.</h1>

<h1 id="toc_486">It automatically returns available as soon as all the slots are covered again.</h1>

<h1 id="toc_487">However sometimes you want the subset of the cluster which is working,</h1>

<h1 id="toc_488">to continue to accept queries for the part of the key space that is still</h1>

<h1 id="toc_489">covered. In order to do so, just set the cluster-require-full-coverage</h1>

<h1 id="toc_490">option to no.</h1>

<h1 id="toc_491">cluster-require-full-coverage yes</h1>

<h1 id="toc_492">In order to setup your cluster make sure to read the documentation</h1>

<h1 id="toc_493">available at <a href="http://redis.io">http://redis.io</a> web site.</h1>

<h6 id="toc_494">############################ SLOW LOG</h6>

<h1 id="toc_495">The Redis Slow Log is a system to log queries that exceeded a specified</h1>

<h1 id="toc_496">execution time. The execution time does not include the I/O operations</h1>

<h1 id="toc_497">like talking with the client, sending the reply and so forth,</h1>

<h1 id="toc_498">but just the time needed to actually execute the command (this is the only</h1>

<h1 id="toc_499">stage of command execution where the thread is blocked and can not serve</h1>

<h1 id="toc_500">other requests in the meantime).</h1>

<h1 id="toc_501">You can configure the slow log with two parameters: one tells Redis</h1>

<h1 id="toc_502">what is the execution time, in microseconds, to exceed in order for the</h1>

<h1 id="toc_503">command to get logged, and the other parameter is the length of the</h1>

<h1 id="toc_504">slow log. When a new command is logged the oldest one is removed from the</h1>

<h1 id="toc_505">queue of logged commands.</h1>

<h1 id="toc_506">The following time is expressed in microseconds, so 1000000 is equivalent</h1>

<h1 id="toc_507">to one second. Note that a negative number disables the slow log, while</h1>

<h1 id="toc_508">a value of zero forces the logging of every command.</h1>

<p>slowlog-log-slower-than 10000</p>

<h1 id="toc_509">There is no limit to this length. Just be aware that it will consume memory.</h1>

<h1 id="toc_510">You can reclaim memory used by the slow log with SLOWLOG RESET.</h1>

<p>slowlog-max-len 128</p>

<h6 id="toc_511">########################## LATENCY MONITOR</h6>

<h1 id="toc_512">The Redis latency monitoring subsystem samples different operations</h1>

<h1 id="toc_513">at runtime in order to collect data related to possible sources of</h1>

<h1 id="toc_514">latency of a Redis instance.</h1>

<h1 id="toc_515">Via the LATENCY command this information is available to the user that can</h1>

<h1 id="toc_516">print graphs and obtain reports.</h1>

<h1 id="toc_517">The system only logs operations that were performed in a time equal or</h1>

<h1 id="toc_518">greater than the amount of milliseconds specified via the</h1>

<h1 id="toc_519">latency-monitor-threshold configuration directive. When its value is set</h1>

<h1 id="toc_520">to zero, the latency monitor is turned off.</h1>

<h1 id="toc_521">By default latency monitoring is disabled since it is mostly not needed</h1>

<h1 id="toc_522">if you don&#39;t have latency issues, and collecting data has a performance</h1>

<h1 id="toc_523">impact, that while very small, can be measured under big load. Latency</h1>

<h1 id="toc_524">monitoring can easily be enabled at runtime using the command</h1>

<h1 id="toc_525">&quot;CONFIG SET latency-monitor-threshold <milliseconds>&quot; if needed.</h1>

<p>latency-monitor-threshold 0</p>

<h6 id="toc_526">####################### EVENT NOTIFICATION</h6>

<h1 id="toc_527">Redis can notify Pub/Sub clients about events happening in the key space.</h1>

<h1 id="toc_528">This feature is documented at <a href="http://redis.io/topics/notifications">http://redis.io/topics/notifications</a></h1>

<h1 id="toc_529">For instance if keyspace events notification is enabled, and a client</h1>

<h1 id="toc_530">performs a DEL operation on key &quot;foo&quot; stored in the Database 0, two</h1>

<h1 id="toc_531">messages will be published via Pub/Sub:</h1>

<h1 id="toc_532">PUBLISH <strong>keyspace@0</strong>:foo del</h1>

<h1 id="toc_533">PUBLISH <strong>keyevent@0</strong>:del foo</h1>

<h1 id="toc_534">It is possible to select the events that Redis will notify among a set</h1>

<h1 id="toc_535">of classes. Every class is identified by a single character:</h1>

<h1 id="toc_536">K     Keyspace events, published with <strong>keyspace@<db></strong> prefix.</h1>

<h1 id="toc_537">E     Keyevent events, published with <strong>keyevent@<db></strong> prefix.</h1>

<h1 id="toc_538">g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...</h1>

<h1 id="toc_539">$     String commands</h1>

<h1 id="toc_540">l     List commands</h1>

<h1 id="toc_541">s     Set commands</h1>

<h1 id="toc_542">h     Hash commands</h1>

<h1 id="toc_543">z     Sorted set commands</h1>

<h1 id="toc_544">x     Expired events (events generated every time a key expires)</h1>

<h1 id="toc_545">e     Evicted events (events generated when a key is evicted for maxmemory)</h1>

<h1 id="toc_546">A     Alias for g$lshzxe, so that the &quot;AKE&quot; string means all the events.</h1>

<h1 id="toc_547">The &quot;notify-keyspace-events&quot; takes as argument a string that is composed</h1>

<h1 id="toc_548">of zero or multiple characters. The empty string means that notifications</h1>

<h1 id="toc_549">are disabled.</h1>

<h1 id="toc_550">Example: to enable list and generic events, from the point of view of the</h1>

<h1 id="toc_551">event name, use:</h1>

<h1 id="toc_552">notify-keyspace-events Elg</h1>

<h1 id="toc_553">Example 2: to get the stream of the expired keys subscribing to channel</h1>

<h1 id="toc_554">name <strong>keyevent@0</strong>:expired use:</h1>

<h1 id="toc_555">notify-keyspace-events Ex</h1>

<h1 id="toc_556">By default all notifications are disabled because most users don&#39;t need</h1>

<h1 id="toc_557">this feature and the feature has some overhead. Note that if you don&#39;t</h1>

<h1 id="toc_558">specify at least one of K or E, no events will be delivered.</h1>

<p>notify-keyspace-events &quot;&quot;</p>

<h6 id="toc_559">######################### ADVANCED CONFIG</h6>

<h1 id="toc_560">Hashes are encoded using a memory efficient data structure when they have a</h1>

<h1 id="toc_561">small number of entries, and the biggest entry does not exceed a given</h1>

<h1 id="toc_562">threshold. These thresholds can be configured using the following directives.</h1>

<p>hash-max-ziplist-entries 512<br/>
hash-max-ziplist-value 64</p>

<h1 id="toc_563">Similarly to hashes, small lists are also encoded in a special way in order</h1>

<h1 id="toc_564">to save a lot of space. The special representation is only used when</h1>

<h1 id="toc_565">you are under the following limits:</h1>

<p>list-max-ziplist-entries 512<br/>
list-max-ziplist-value 64</p>

<h1 id="toc_566">Sets have a special encoding in just one case: when a set is composed</h1>

<h1 id="toc_567">of just strings that happen to be integers in radix 10 in the range</h1>

<h1 id="toc_568">of 64 bit signed integers.</h1>

<h1 id="toc_569">The following configuration setting sets the limit in the size of the</h1>

<h1 id="toc_570">set in order to use this special memory saving encoding.</h1>

<p>set-max-intset-entries 512</p>

<h1 id="toc_571">Similarly to hashes and lists, sorted sets are also specially encoded in</h1>

<h1 id="toc_572">order to save a lot of space. This encoding is only used when the length and</h1>

<h1 id="toc_573">elements of a sorted set are below the following limits:</h1>

<p>zset-max-ziplist-entries 128<br/>
zset-max-ziplist-value 64</p>

<h1 id="toc_574">HyperLogLog sparse representation bytes limit. The limit includes the</h1>

<h1 id="toc_575">16 bytes header. When an HyperLogLog using the sparse representation crosses</h1>

<h1 id="toc_576">this limit, it is converted into the dense representation.</h1>

<h1 id="toc_577">A value greater than 16000 is totally useless, since at that point the</h1>

<h1 id="toc_578">dense representation is more memory efficient.</h1>

<h1 id="toc_579">The suggested value is ~ 3000 in order to have the benefits of</h1>

<h1 id="toc_580">the space efficient encoding without slowing down too much PFADD,</h1>

<h1 id="toc_581">which is O(N) with the sparse encoding. The value can be raised to</h1>

<h1 id="toc_582">~ 10000 when CPU is not a concern, but space is, and the data set is</h1>

<h1 id="toc_583">composed of many HyperLogLogs with cardinality in the 0 - 15000 range.</h1>

<p>hll-sparse-max-bytes 3000</p>

<h1 id="toc_584">Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in</h1>

<h1 id="toc_585">order to help rehashing the main Redis hash table (the one mapping top-level</h1>

<h1 id="toc_586">keys to values). The hash table implementation Redis uses (see dict.c)</h1>

<h1 id="toc_587">performs a lazy rehashing: the more operation you run into a hash table</h1>

<h1 id="toc_588">that is rehashing, the more rehashing &quot;steps&quot; are performed, so if the</h1>

<h1 id="toc_589">server is idle the rehashing is never complete and some more memory is used</h1>

<h1 id="toc_590">by the hash table.</h1>

<h1 id="toc_591">The default is to use this millisecond 10 times every second in order to</h1>

<h1 id="toc_592">actively rehash the main dictionaries, freeing memory when possible.</h1>

<h1 id="toc_593">If unsure:</h1>

<h1 id="toc_594">use &quot;activerehashing no&quot; if you have hard latency requirements and it is</h1>

<h1 id="toc_595">not a good thing in your environment that Redis can reply from time to time</h1>

<h1 id="toc_596">to queries with 2 milliseconds delay.</h1>

<h1 id="toc_597">use &quot;activerehashing yes&quot; if you don&#39;t have such hard requirements but</h1>

<h1 id="toc_598">want to free memory asap when possible.</h1>

<p>activerehashing yes</p>

<h1 id="toc_599">The client output buffer limits can be used to force disconnection of clients</h1>

<h1 id="toc_600">that are not reading data from the server fast enough for some reason (a</h1>

<h1 id="toc_601">common reason is that a Pub/Sub client can&#39;t consume messages as fast as the</h1>

<h1 id="toc_602">publisher can produce them).</h1>

<h1 id="toc_603">The limit can be set differently for the three different classes of clients:</h1>

<h1 id="toc_604">normal -&gt; normal clients including MONITOR clients</h1>

<h1 id="toc_605">slave  -&gt; slave clients</h1>

<h1 id="toc_606">pubsub -&gt; clients subscribed to at least one pubsub channel or pattern</h1>

<h1 id="toc_607">The syntax of every client-output-buffer-limit directive is the following:</h1>

<h1 id="toc_608">client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds></h1>

<h1 id="toc_609">A client is immediately disconnected once the hard limit is reached, or if</h1>

<h1 id="toc_610">the soft limit is reached and remains reached for the specified number of</h1>

<h1 id="toc_611">seconds (continuously).</h1>

<h1 id="toc_612">So for instance if the hard limit is 32 megabytes and the soft limit is</h1>

<h1 id="toc_613">16 megabytes / 10 seconds, the client will get disconnected immediately</h1>

<h1 id="toc_614">if the size of the output buffers reach 32 megabytes, but will also get</h1>

<h1 id="toc_615">disconnected if the client reaches 16 megabytes and continuously overcomes</h1>

<h1 id="toc_616">the limit for 10 seconds.</h1>

<h1 id="toc_617">By default normal clients are not limited because they don&#39;t receive data</h1>

<h1 id="toc_618">without asking (in a push way), but just after a request, so only</h1>

<h1 id="toc_619">asynchronous clients may create a scenario where data is requested faster</h1>

<h1 id="toc_620">than it can read.</h1>

<h1 id="toc_621">Instead there is a default limit for pubsub and slave clients, since</h1>

<h1 id="toc_622">subscribers and slaves receive data in a push fashion.</h1>

<h1 id="toc_623">Both the hard or the soft limit can be disabled by setting them to zero.</h1>

<p>client-output-buffer-limit normal 0 0 0<br/>
client-output-buffer-limit slave 256mb 64mb 60<br/>
client-output-buffer-limit pubsub 32mb 8mb 60</p>

<h1 id="toc_624">Redis calls an internal function to perform many background tasks, like</h1>

<h1 id="toc_625">closing connections of clients in timeout, purging expired keys that are</h1>

<h1 id="toc_626">never requested, and so forth.</h1>

<h1 id="toc_627">Not all tasks are performed with the same frequency, but Redis checks for</h1>

<h1 id="toc_628">tasks to perform according to the specified &quot;hz&quot; value.</h1>

<h1 id="toc_629">By default &quot;hz&quot; is set to 10. Raising the value will use more CPU when</h1>

<h1 id="toc_630">Redis is idle, but at the same time will make Redis more responsive when</h1>

<h1 id="toc_631">there are many keys expiring at the same time, and timeouts may be</h1>

<h1 id="toc_632">handled with more precision.</h1>

<h1 id="toc_633">The range is between 1 and 500, however a value over 100 is usually not</h1>

<h1 id="toc_634">a good idea. Most users should use the default of 10 and raise this up to</h1>

<h1 id="toc_635">100 only in environments where very low latency is required.</h1>

<p>hz 10</p>

<h1 id="toc_636">When a child rewrites the AOF file, if the following option is enabled</h1>

<h1 id="toc_637">the file will be fsync-ed every 32 MB of data generated. This is useful</h1>

<h1 id="toc_638">in order to commit the file to the disk more incrementally and avoid</h1>

<h1 id="toc_639">big latency spikes.</h1>

<p>aof-rewrite-incremental-fsync yes</p>


    

      </div>

      <div class="row">
        <div class="large-6 columns">
        <p class="text-left" style="padding:15px 0px;">
      
          <a href="14499219679904.html" 
          title="Previous Post: du df ">&laquo; du df </a>
      
        </p>
        </div>
        <div class="large-6 columns">
      <p class="text-right" style="padding:15px 0px;">
      
          <a  href="14498902282643.html" 
          title="Next Post: redis3.0 ">redis3.0  &raquo;</a>
      
      </p>
        </div>
      </div>
      <div class="comments-wrap">
        <div class="share-comments">
          

          

          
        </div>
      </div>
    </div><!-- article-wrap -->
  </div><!-- large 8 -->




 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="asset/img/icon.jpg" /></div>
            
                <h1>IT framer</h1>
                <div class="site-des">just in the dark hole</div>
                <div class="social">

<a target="_blank" class="google" href="https://plus.google.com/u/0/?tab=wX" rel="author" title="Google+">Google+</a>







<a target="_blank" class="github" target="_blank" href="https://github.com/jettyaway" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:727913675@qq.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="flume.html"><strong>flume</strong></a>
        
            <a href="java.html"><strong>java</strong></a>
        
            <a href="kafka.html"><strong>kafka</strong></a>
        
            <a href="awk.html"><strong>awk</strong></a>
        
            <a href="storm.html"><strong>storm</strong></a>
        
            <a href="spark.html"><strong>spark</strong></a>
        
            <a href="redis.html"><strong>redis</strong></a>
        
            <a href="liunx.html"><strong>linux</strong></a>
        
            <a href="zookeeper.html"><strong>zookeeper</strong></a>
        
            <a href="hive.html"><strong>hive</strong></a>
        
            <a href="maven.html"><strong>maven</strong></a>
        
            <a href="shell.html"><strong>shell</strong></a>
        
            <a href="docker.html"><strong>docker</strong></a>
        
            <a href="mysql.html"><strong>mysql</strong></a>
        
            <a href="datahole.html"><strong>datahole</strong></a>
        
            <a href="scala.html"><strong>scala</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15441960974362.html">shell whilessh</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15011626313885.html">java double </a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14967618384549.html">docker </a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14965523697004.html"> Dockerfile </a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14962015887709.html">shell8: $(())$()${}</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    <script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
